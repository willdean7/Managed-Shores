# Code Folder README

This README provides documentation and guidance for the `code` folder of the Managed_Shores project. It outlines the folder structure, describes the main data files and scripts, and provides instructions for usage and best practices.

---

## Folder Structure

- **raw/**: Contains all original, unmodified data and script files received from collaborators or external sources. Do not edit files in this folder directly.
- **processed/**: Contains all cleaned, transformed, or derived datasets generated during analysis. All outputs from scripts should be saved here for reproducibility.
- **README.md**: This documentation file for the data folder.

---

## File Descriptions

| File/Folder Name         | Description                                                                                              | Source/Author                | Notes                                      |
|------------------------- |----------------------------------------------------------------------------------------------------------|------------------------------|--------------------------------------------|
| `waves_ms.R`                | Estimates wave run-up and coastal slope parameters, processes California coastline data, and generates annual maximum wave run-up values for flood and damage modeling. | Jonah Danzinger   | Uses NOAA buoy data and Natural Earth shapefiles. Requires spatial and elevation R packages. |
| `redfin_data_code_ms.R`     | Aggregates and cleans Redfin property sales data, scrapes rental value estimates, performs regression to estimate missing rental values, and joins with demographic data. | Jonah Danzinger     | Integrates US Census tract-level variables. Outputs processed property datasets.             |
| `MSGRP_valuationcode_ms.R`  | Integrates property, land value, and wave/run-up data for financial modeling; models sea level rise, predicts flood damages, and calculates net present value (NPV) of rental income and damages. | Jonah Danzinger    | Requires processed Redfin and land value data. Includes logistic and quadratic modeling.      |
| `raw/`                   | Folder containing all original, unmodified data and script files, including those received from collaborators (e.g., student scripts and raw property CSVs). | Various (see file metadata)  | Do not modify files in this folder directly.                                                 |
| `processed/`             | Folder for cleaned, transformed, or derived datasets created during analysis.           | Generated by project scripts | Save all processed outputs here for reproducibility.        |
| `waves_ms_parcel.R`      | Generates parcel-level, spatially explicit wave run-up estimates by mapping each property to its nearest coastal point and assigning a time series of annual max run-up. | William Dean    | Enables property-scale flood and damage modeling. Integrates with Redfin parcel data.                                                            |
| `calc_vulnerability_metrics.R` | Function that Calculates economic, physical, and combined vulnerability metrics for each property, labels primary risk drivers, and assigns categorical risk levels for mapping and dashboards. | William Dean    | Used as a post-processing step after risk and retreat modeling. Outputs vulnerability metrics datasets.                                                       |
| `comparisons.R`         | Launches an interactive Shiny dashboard to visualize, compare, and analyze property-level vulnerability and retreat timing. Features maps, plots, and neighbor comparisons. | William Dean    | Requires processed property datasets with vulnerability metrics.                                                                   |

---

## Data Processing Workflow

- **Original files** are kept in `raw/` to preserve data provenance.
- **Processed files** are saved in `processed/` after cleaning or transformation by project scripts with "_ms" suffix to indicate they are part of the Managed Shores project (e.g. 'waves_ms.R').
- **Do not modify files in `raw/` directly**; always save new or modified versions in `processed/'.

---

## Usage Instructions

1. **Importing Data and Scripts**: Place all original `.R` scripts and `.csv` data files received from collaborators into the `raw/` folder.
2. **Processing Data**: Run the provided scripts (e.g., `redfin_data_code.R`, `waves.R`) to generate cleaned or transformed datasets, saving outputs in `processed/`.
3. **Documentation**: Update this README as you add new files or make changes to existing datasets or scripts.

---

## Best Practices

- **Consistent Naming**: Use clear, descriptive names for all files and folders.
- **Documentation**: Keep this README up to date with descriptions of new or modified files.
- **Version Control**: Track changes to scripts and documentation using Git, but consider excluding very large datasets using `.gitignore` if needed.
- **Metadata**: For each dataset, provide a brief description, source, and relevant notes in this README or a separate metadata file.

---

---

## Contact

For questions about specific files or data sources, please refer to the file descriptions above or contact the repository owner (willdean7).

---
